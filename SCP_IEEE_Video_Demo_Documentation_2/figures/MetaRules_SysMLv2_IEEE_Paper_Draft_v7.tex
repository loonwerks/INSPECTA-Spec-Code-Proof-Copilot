
\documentclass[conference]{IEEEtran}

% -------------------- Core IEEE / formatting --------------------
\usepackage{float}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{flushend}
\usepackage{cite}
\usepackage{url}
\usepackage[hidelinks]{hyperref}

% -------------------- Math / theorem --------------------
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

% -------------------- Figures / tables --------------------
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{chngcntr}
\counterwithout{figure}{section}

% -------------------- Lists / compact spacing --------------------
\usepackage{paralist}

% -------------------- Algorithms (boxed style, IEEE-friendly) --------------------
\usepackage[ruled,vlined]{algorithm2e}
\DontPrintSemicolon
\SetKwInput{KwIn}{Input}
\SetKwInput{KwOut}{Output}
\SetKw{KwTo}{to}
\SetKw{KwOr}{or}

% -------------------- Code blocks (for GUMBO snippets and rule appendix) --------------------
\usepackage{listings}
% Setup for listings style (shared with demo/short-report)
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=tb,
    captionpos=b,
    backgroundcolor=\color{gray!5},
    commentstyle=\color{green!50!black},
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    showstringspaces=false
}

% -------------------- Author notes --------------------
\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO}: {#1}}}

% -------------------- Figures folder convenience --------------------
\graphicspath{{figures/}}

% -------------------- Safe include helper: compile even if figures are missing --------------------
\newcommand{\safeincludegraphics}[2][]{%
  \IfFileExists{#2}{%
    \includegraphics[#1]{#2}%
  }{%
    \fbox{\parbox{0.95\linewidth}{\textbf{Missing figure:} #2\\
    (Placeholder. Upload this file to the \texttt{figures/} folder.)}}%
  }%
}

\begin{document}

\title{Evaluation-Driven Neuro-Symbolic Contract Generation in SysML v2 using Meta-Rules}

\author{\IEEEauthorblockN{
Amer Tahat, David Hardin, Isaac Amundson, and Darren Coffer}
\IEEEauthorblockA{Applied Research and Technology, Collins Aerospace, USA\\
{\{first.last\}@collins.com}}
}

\maketitle

\begin{abstract}
Neuro-symbolic approaches seek to combine the generalization capabilities of large language models (LLMs) with the rigor and trust guarantees of formal methods, offering a promising path for trustworthy model-based systems engineering (MBSE). In practice, adoption is limited by the difficulty of adapting LLMs to rapidly evolving modeling languages, verification frameworks, and system semantics. Fine-tuning state-of-the-art commercial models is often infeasible due to vendor restrictions, cost, or lack of access, and even when possible typically targets earlier model versions and requires labeled datasets that do not exist for newly introduced SysML~v2/GUMBO features.

This paper presents an evaluation-driven neuro-symbolic copilot, \emph{Spec--Code--Proof (SCP)}, for requirement-to-contract formalization in SysML~v2 using GUMBO, integrated within the INSPECTA toolchain. Rather than relying on fine-tuning, SCP leverages LLMs as heuristic generators and enforces correctness through closed-loop interaction with formal verification and code-generation tools (HAMR and Logika), producing verified Scala/Slang artifacts and proof obligations. Central to SCP is a novel \emph{Meta-Rules} method: reusable formalization strategies learned from a small number of verified examples and incrementally refined using verification feedback under bounded repair and budget constraints.

We evaluate SCP on a realistic long-context benchmark of 40+ natural-language requirements derived from an open-source $\approx$150-page Collins corpus (including the Isolette case study). A prompt-only baseline fails to normalize a single GUMBO block after 33 minutes despite consuming 19.0M input tokens (18.0M cached), 85K output tokens, and 54K reasoning tokens. With Meta-Rules, SCP achieves 100\% verification success in 25 minutes while reducing total input tokens to 4.9M (4.3M cached; $\approx$200K uncached), output tokens to 51K, and reasoning tokens to 34K, improving throughput from 0.030 to 1.760 tasks/min ($58.7\times$).
\end{abstract}

\vspace{8pt}
\noindent\textbf{Distribution Statement A.} Approved for public release: distribution unlimited.


%====================================================================
\section{Introduction and Motivation}
\label{sec:intro}

Neuro-symbolic reasoning has gained increasing attention as a means to combine the expressive power of data-driven learning with the rigor and trust guarantees of symbolic methods. LLMs, in particular, have demonstrated strong capabilities in interpreting natural-language artifacts and synthesizing structured representations. However, their effective use in safety- and mission-critical MBSE workflows remains constrained by practical limitations in model adaptation, data availability, and toolchain evolution.

A fundamental challenge arises from the dependence of LLM performance on pretraining coverage. When the target application aligns closely with a model's original training distribution, strong results can often be achieved with minimal additional effort. In contrast, when engineers apply LLMs to emerging modeling languages, newly introduced semantic constructs, or rapidly evolving verification infrastructures, performance can degrade sharply. Addressing this gap typically requires fine-tuning, which is often infeasible for the latest commercial models due to vendor restrictions, cost, or lack of access. Even when fine-tuning is possible, it frequently targets earlier or less capable model versions and requires substantial labeled datasets that do not exist for newly developed tools or language features. This limitation is especially impactful for researchers and practitioners pushing the state of the art, where innovation outpaces data availability.

These challenges are particularly evident in MBSE environments that aim to integrate modeling, contract specification, formal verification, code generation, and DevOps-style workflows. The INSPECTA toolchain exemplifies this trend by supporting automation across large engineering teams to enable a trustworthy end-to-end MBSE lifecycle~\cite{hardin2025dasc}. INSPECTA integrates SysML~v2 architectural modeling, contract-based reasoning, formal analysis, and automated artifact generation, with an emphasis on scalability and assurance. In such settings, relying on brittle prompt engineering or repeated model fine-tuning is impractical; instead, mechanisms are needed to capture expert reasoning, reuse formalization knowledge, and adapt continuously as tools and languages evolve.

This paper presents \emph{Spec--Code--Proof (SCP)}, an evaluation-driven neuro-symbolic copilot for formalizing natural-language requirements into SysML~v2/GUMBO contracts and automatically generating verification-ready artifacts within INSPECTA. SCP uses LLMs as heuristic generators but closes the loop with the HAMR/Logika verification toolchain to produce verified Scala/Slang artifacts and associated proof obligations. Our central technical contribution is a novel \emph{Meta-Rules} methodology that extracts transferable formalization strategies from golden examples, validates them through verification feedback, and reuses them across requirements under bounded time/token budgets and limited automated repair cycles.

\subsection{Contributions}
\label{sec:contrib}
We make the following contributions:
\begin{compactitem}
  \item \textbf{SCP Copilot for SysML~v2/GUMBO:} a closed-loop neuro-symbolic copilot that translates English requirements into GUMBO contracts and drives INSPECTA/HAMR/Logika to generate Scala/Slang code artifacts and proofs with minimal human intervention.
  \item \textbf{Meta-Rules:} a verification-backed knowledge representation for persistent, reusable formalization strategies, retained only when they generalize and verify under bounded budgets.
  \item \textbf{Formal algorithm:} an explicit algorithmic description of Meta-Rule extraction, validation, retention, and verification-guided repair.
  \item \textbf{Realistic long-context evaluation:} a benchmark derived from a Collins open-source $\approx$150-page natural-language requirements corpus (including Isolette), with mixed textual and diagrammatic representations.
  \item \textbf{Quantitative results:} Meta-Rules improve throughput from 0.030 to 1.760 tasks/min ($58.7\times$) and achieve 100\% verification success on 40+ requirements while substantially reducing token and reasoning cost compared to a prompt-only baseline.
\end{compactitem}


%====================================================================
\section{Neuro-Symbolic Background and Related Work}
\label{sec:related}

\subsection{INSPECTA, SysML v2, and Verification-Enhanced Code Generation}
INSPECTA leverages SysML v2 to provide a rigorous architectural framework for reasoning about distributed embedded systems and organizing assurance evidence across refinement layers~\cite{hardin2025dasc}. Its toolchain integrates assume/guarantee contracts, formal verification, and skeletal code generation. HAMR provides multi-platform code generation, and recent development targets memory-safe languages such as Rust with Verus specifications, enabling proofs at the code level that refine system-level contracts~\cite{hardin2025dasc}.

\subsection{AGREE, GUMBO, HAMR, and Logika}
Compositional assume/guarantee verification for architecture models has been operationalized in tools such as AGREE, and GUMBO provides a contract language that better supports code-level checking and integration with implementation semantics~\cite{hardin2025dasc}. The HAMR ecosystem and its associated verification tooling (e.g., Logika/Slang) provide an end-to-end pipeline for model-based development with proof artifacts. The Isolette system serves as a widely used pedagogical and benchmarking example for illustrating such end-to-end workflows~\cite{hatcliff2024isolette}.

\subsection{Neuro-Symbolic Copilots for Proof Engineering}
Neuro-symbolic copilots couple LLM generation with symbolic tool feedback (e.g., failed proof obligations, counterexamples) to enable iterative repair and reduce user effort. AGREEDog presents a representative copilot architecture for contract-centric workflows and emphasizes evaluation metrics that combine correctness, tool feedback, and resource cost~\cite{tahat2025agreedog}. Our work complements this direction by focusing on SysML v2/GUMBO contract generation and introducing persistent Meta-Rules as reusable formalization knowledge retained through verification.

%====================================================================
\section{SysML v2 Tutorial}
\label{sec:sysmlv2}
\todo{Reserved for a brief SysML v2 tutorial.}

%====================================================================
\section{GUMBO Contracts}
\label{sec:gumbo}

GUMBO contracts express assumptions and guarantees for SysML v2 components, supporting compositional reasoning at the model level and refinement to implementation-level specifications. A typical GUMBO block includes optional state variables, initialization guarantees, assumptions constraining inputs, global guarantees, and \texttt{compute\_cases} clauses aligning conditional requirements with case-specific guarantees.

% Source: hardin2025dasc.pdf, Fig. 1 (SysML v2 model with GUMBO contracts) and Sec. III for assume/guarantee discussion.

Listing~\ref{lst:gumbo-skel} provides an illustrative skeleton.

\begin{lstlisting}[caption={Illustrative skeleton of a SysML v2 component with a GUMBO contract.},label={lst:gumbo-skel}]
language "GUMBO" /*{
  state lastCmd: On_Off;
  initialize
    guarantee initLastCmd: lastCmd == Off;

  compute
    assume lowerLEUpper: lower <= upper;
    guarantee lastCmdTracksOutput: lastCmd == heat_control;

  compute_cases
    case REQ_1:
      assume mode == INIT;
      guarantee heat_control == Off;
    case REQ_2:
      assume mode == NORMAL && temp < lower;
      guarantee heat_control == On;
} */
\end{lstlisting}

%====================================================================
\section{Neuro-Symbolic Contract Generation with Meta-Rules}
\begin{figure}[t]
  \centering
  \safeincludegraphics[width=\linewidth]{copilot_loop.png}
  \caption{SCP Copilot self-healing neuro-symbolic code generation loop. The copilot parses English requirements, applies Meta-Rules, invokes SysML~v2/Sireum parsing and the HAMR/Logika verification toolchain, and uses bounded repair (with minimal human hints) before generating verified artifacts.}
  \label{fig:workflow}
\end{figure}

\label{sec:approach}

\subsection{Baseline Results and Limitations}
We first evaluated a direct formalization baseline using Codex GPT-5.1 max, tasked with translating English requirements into normalized SysML v2/GUMBO contracts. Although the model produced syntactically plausible outputs, it failed to correctly normalize any GUMBO block after approximately 33 minutes. The failure was accompanied by extreme computational cost: \(\sim 19.0\)M input tokens, \(\sim 18.0\)M cached tokens, \(\sim 85\)K output tokens, and \(\sim 54\)K reasoning tokens, yielding \(<0.05\) verified requirements and \(0\%\) code-level success.

% Source: attached progress slides screenshot, p.3 (Baseline Results and Limitations) and Fig.2 caption + chart values.

\begin{lstlisting}[
  caption={Excerpt of retained human-expert Meta-Rules (Set~1) for English-to-GUMBO formalization. Line numbers are shown for reference.},
  label={list:metaRules},
  numbers=left,
  firstnumber=1,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=6pt
]
WHEN TO USE EACH SECTION (Meta-Rules Set 1)
-------------------------------------------
2.1 state
- Add if the English requirement requires memory:
  * Hysteresis: "shall not be changed" / "hold previous"
    (e.g., heat within desired band; alarm no-change band).
  * Timeouts: (duration in mode > 1.0 s) if not directly available
    from the platform as a primitive.
  Pattern examples:
    lastHeat: Isolette_Data_Model::On_Off
    initElapsed: Base_Types::S64  // time units per modeling conventions

2.2 functions
- Add pure helper predicates for reusable logic, e.g.:
    def in_reset_band(t, lo, hi): Boolean :=
        lo + 0.5[s32] <= t & t <= hi - 0.5[s32]

2.3 integration.guarantee
- Use integration.guarantee when your element is the producer of a property that:
  * Must hold for all time (init + compute);
  * Is not contingent on a transient case condition (e.g., mode or alarm band); and
  * Is best treated as a cross-interface invariant (e.g., ordering, units, encoding domain).
- Place environmental assumptions (EA-*). Typical content:
  * Sensor temperature range/units/precision (A.3.2).
  * Isolette warm/cool slew limits +/-1F/min (A.3.1) -- used to justify latency.
  * Operator Interface ranges and ordering of desired/alarm temps (A.3.4).
  Example:
    assume Table_A_12_LowerAlarmTemp "...|#page=112":
      96 [s32] <= lower_alarm_tempWstatus.degrees &
      lower_alarm_tempWstatus.degrees <= 101 [s32];
\end{lstlisting}

\noindent\textbf{How to read the excerpt.}
In Listing~\ref{list:metaRules}, lines~3--11 capture linguistic triggers
(e.g., ``hold previous'', hysteresis, timeouts) that indicate hidden temporal dependence.
A human expert would often represent such requirements using a small state machine or
stateful contract; SCP uses these patterns to justify introducing explicit GUMBO
\texttt{state}/\texttt{initialize} structure and canonical state variables (lines~8--9).
Lines~13--16 show reusable helper predicates that reduce repeated logical scaffolding across
requirements. Lines~18--25 encode guidance for integration-level invariants and environmental
assumptions (including traceable, source-anchored constraints), which are crucial for avoiding
spurious counterexamples during verification.
This excerpt is produced via semi-automatic error analysis: after the prompt-only baseline fails,
SCP asks the copilot to infer an initial candidate Meta-Rule set, then incrementally refines it
with verification feedback and (when needed) light human edits; rules are retained only when they
generalize and verify within bounded time/token/repair budgets.


\subsection{Algorithm}
Algorithm~\ref{alg:meta-rules} formalizes Meta-Rule learning, application, and bounded repair.

\begin{algorithm}[t]
\caption{SCP Meta-Rules Learning, Application, and Verification-Guided Repair}
\label{alg:meta-rules}
\KwIn{Requirements set $R$; golden examples $G$ (English + normalized GUMBO); verifier $V$ (HAMR/Logika); budgets $B$ (time/tokens/repair cycles); similarity threshold $\epsilon$; acceptance threshold $\tau$.}
\KwOut{Verified contracts $C$; retained Meta-Rules library $M$; flagged failures $F$.}

\textbf{Initialization:}\\
$M \leftarrow \emptyset$ \tcp*{persistent rule memory}
$C \leftarrow \emptyset$; $F \leftarrow \emptyset$\\

\BlankLine
\textbf{Phase I: Meta-Rule extraction and validation}\\
\ForEach{$(r_g, g_g) \in G$}{
  $m \leftarrow \textsc{ExtractRule}(r_g, g_g)$\;
  $okCount \leftarrow 0$\;
  \ForEach{$r \in \textsc{Sample}(R)$}{
    $\hat{g} \leftarrow \textsc{ApplyRule}(m, r)$\;
    \If{$\textsc{Distance}(\hat{g}, g_g) > \epsilon$}{\textbf{continue}\;}
    $(ok, fb) \leftarrow V(\hat{g}, B)$\;
    \While{\textnormal{not} $ok$ \textbf{and} \textsc{RepairBudgetRemaining}$(B)$}{
      $\hat{g} \leftarrow \textsc{Repair}(\hat{g}, fb, B)$\;
      $(ok, fb) \leftarrow V(\hat{g}, B)$\;
    }
    \If{$ok$}{$okCount \leftarrow okCount + 1$\;}
  }
  \eIf{$okCount \ge \tau$}{
    $M \leftarrow M \cup \{m\}$ \tcp*{retain only if it verifies and generalizes}
  }{
    \textsc{DiscardOrRefineWithHuman}$(m)$\;
  }
}

\BlankLine
\textbf{Phase II: Rule-guided formalization with bounded repair}\\
\ForEach{$r \in R$}{
  $\hat{g} \leftarrow \textsc{SynthesizeWithRules}(r, M)$\;
  $(ok, fb) \leftarrow V(\hat{g}, B)$\;
  \While{\textnormal{not} $ok$ \textbf{and} \textsc{RepairBudgetRemaining}$(B)$}{
    $\hat{g} \leftarrow \textsc{Repair}(\hat{g}, fb, B)$\;
    $(ok, fb) \leftarrow V(\hat{g}, B)$\;
  }
  \eIf{$ok$}{
    $C \leftarrow C \cup \{(r,\hat{g})\}$\;
  }{
    $F \leftarrow F \cup \{(r,\hat{g},fb)\}$\;
  }
}

\BlankLine
\textbf{Quality assessment and logging:}\\
Log timestamps, token usage, latency, and repair count; store $M$ for reuse.

\end{algorithm}


%====================================================================
\section{Illustrative Example: Isolette Counterexample-Driven Repair}
\label{sec:example}

We illustrate the workflow using an Isolette-derived requirement where an initial contract candidate fails verification and is repaired using Meta-Rule guidance. Figure~\ref{fig:example-conversation} provides a representative interaction trace (snapshot-based).

% (Figure placeholder) The interaction snapshot will be added in a later revision.
% Expected file: figures/conversation_example.png (or similar)

\todo{Next revision: include the English requirement, the initial GUMBO candidate, a short counterexample summary, and the repaired contract fragment.}

%====================================================================
\section{Benchmark and Results}
\begin{figure}[t]
  \centering
  \safeincludegraphics[width=\linewidth]{failure-message.png}
  \caption{Baseline failure excerpt for direct LLM formalization in SysML~v2/GUMBO. Despite very high token usage, the model fails to produce a tool-accepted GUMBO block, motivating an approach that extracts and reuses transferable formalization knowledge (Meta-Rules) rather than relying on model fine-tuning.}
  \label{fig:baselineFailure}
\end{figure}

\label{sec:results}

\subsection{Benchmark}
We constructed a custom benchmark to guide the SCP Copilot through both formalization and verification. The benchmark includes 40+ English requirements drawn from an open-source \(\approx\)150-page Collins document spanning multiple systems (including the Isolette). The corpus is written entirely in natural English and contains no SysML v2 or AADL specifications. It also includes mixed representations (e.g., figures illustrating state machines rather than purely textual descriptions). As such, the benchmark represents a realistic long-context requirement formalization challenge, combining unstructured documentation, informal tables, and heterogeneous representations. Importantly, only one GUMBO block (\(\approx 12\%\) of the dataset) was used for Meta-Rule refinement.

% Source: attached progress slides screenshot, p.5 (Benchmark and Quantitative Evaluation).

\subsection{Quantitative Results}
Despite limited supervision, the SCP Copilot successfully formalized all 40+ requirements from English into GUMBO, generated supporting infrastructure code, and passed HAMR integration-level and code-level verification conditions.

% Source: attached progress slides screenshot, p.5 bullets.

Meta-Rules enabled 100\% correctness in approximately 25 minutes (including human final approvals) and dramatically reduced token and reasoning overhead. Figure~\ref{fig:resultsChart} and Table~\ref{tab:results} summarize the before/after comparison. Compared to the baseline, the Meta-Rules workflow improves task throughput from 0.030 tasks/min to 1.760 tasks/min (a $58.7\times$ increase), transforming a failing workflow into a fully verified one.

% Source: attached progress slides screenshot, p.5--p.6 (bullets) and Fig.4 chart values.

\begin{table}[t]
\centering
\caption{Performance before and after Meta-Rules (Codex GPT-5.1 max). Values reflect the charted measurements.}
\label{tab:results}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{Baseline} & \textbf{With Meta-Rules} \\
\midrule
Verified requirements & $<0.05$ of sample & 40+/40+ (100\%) \\
Code-level success & 0\% & 100\% \\
Wall-clock time (min) & 33 & 25 \\
Input tokens (M) & 19.0 & 4.9 \\
Cached tokens (M) & 18.0 & 4.3 \\
Output tokens (K) & 85 & 51 \\
Reasoning tokens (K) & 54 & 34 \\
Throughput (tasks/min) & 0.030 & 1.760 \\
\bottomrule
\end{tabular}
% Source: attached progress slides screenshot, Fig.4 (bar labels) + accompanying bullet text.
\end{table}

\begin{figure}[t]
  \centering
  \safeincludegraphics[width=\linewidth]{results_chart.png}
  \caption{Codex GPT-5.1 max performance comparison before (orange) and after (blue) Meta-Rules. Meta-Rules reduce token usage by orders of magnitude, cut execution time, and enable 100\% verification success, improving throughput from 0.030 to 1.760 tasks/min.}
  \label{fig:resultsChart}
  % Source: attached progress slides screenshot, Fig.4 caption + bar labels.
\end{figure}

\subsection{Threats to Validity}
\textbf{Internal validity.} Correctness is measured by toolchain verification; limitations or bugs in verification backends could affect outcomes. 
\textbf{External validity.} The benchmark focuses on one corpus and domain; other domains may require additional Meta-Rules.
\textbf{Construct validity.} Verification success does not fully capture stakeholder intent in natural-language requirements.
\textbf{Conclusion validity.} Absolute cost depends on infrastructure and caching behavior, but the relative improvements are robust.

%====================================================================
\section{Conclusion and Future Work}
\label{sec:conclusion}

We presented an evaluation-driven neuro-symbolic approach to generating SysML v2/GUMBO contracts without fine-tuning. Meta-Rules capture reusable formalization knowledge and are retained only when they generalize and verify under bounded repair budgets, converting an expensive failing baseline into an efficient, fully verified workflow.

Ongoing work extends the current Scala-based HAMR evaluation to Rust/Verus and applies the approach to a more complex DroneWorks firewall case study, including a SysML v2 firewall model with GUMBO-style comments developed by Collins. We also plan to explore automatic translation from native SysML v2 requirements representations to GUMBO to further reduce token consumption, submit a paper, and release the Meta-Rules framework as open source.

% Source: attached progress slides screenshot, p.6 (Ongoing and next steps).

%====================================================================
\appendix
\section{Meta-Rules File}
\label{app:rules}
\todo{Insert the complete Meta-Rules file here.}

\begin{lstlisting}[caption={Meta-Rules (placeholder).},label={lst:rules}]
# TODO: Paste complete rules file here.
\end{lstlisting}

%====================================================================
\bibliographystyle{IEEEtran}
\bibliography{biblio_v5}

\end{document}
