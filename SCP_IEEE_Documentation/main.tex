\documentclass[conference]{IEEEtran}

\usepackage{float}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{flushend}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{amsthm}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO}: {#1}}}

\newcommand{\review}[2]{#1}


\usepackage{algorithm}
\usepackage{algpseudocode}


\usepackage{xcolor,colortbl}
\usepackage{mathpartir}
\usepackage{tikz}
\usepackage{url}
\usepackage{subcaption}

\usetikzlibrary{arrows,arrows.meta,calc,positioning,backgrounds,fit,shapes,shadows,trees}

\usepackage{paralist}
\usepackage{boxedminipage}
\usepackage{booktabs}
\usepackage{chngcntr}
\counterwithout{figure}{section}

\begin{document}

\title{New paper}

\author{\IEEEauthorblockN{
Amer Tahat, David Hardin, Isaac Amundson, and Darren Cofer}
\IEEEauthorblockA{Applied Research and Technology, Collins Aerospace, USA\\
{\{first.last\}@collins.com}}
}

\maketitle

\begin{abstract}
This document is meant to illustrate the key moments of the Demo video. The full video is about +20 minutes, we will only present 5-6 minutes, given the time limitation, so this will give more detailed artifacts for interested readers. 
% CITE: INSPECTA toolchain (Hardin et al., DASC 2025).
% CITE: HAMR, Logika, SysML v2, Isolette (Hatcliff et al., ISOLA 2024).
% CITE: Neuro-symbolic background and AGREEDog (AISOLA 2025).
\end{abstract}


\vspace{12pt}
\noindent
\textbf{Distribution Statement A.} Approved for public release: distribution unlimited.

%--------------------------------------------------------------------
\section{Introduction and Motivation}
\label{sec:introduction}

Neuro-symbolic reasoning has emerged as a promising paradigm for combining the flexibility of data-driven learning with the rigor of formal verification. In particular, large language models (LLMs) offer powerful capabilities for interpreting natural-language requirements and synthesizing structured artifacts. However, their effective integration into safety- and mission-critical workflows remains challenging.

A central limitation arises from the dependency of LLM performance on pretraining coverage. When an application domain aligns closely with the model’s pretraining data, strong performance can often be achieved with little additional effort. In contrast, when engineers seek to apply LLMs to newly evolving modeling languages, novel semantic constructs, or emerging toolchains, performance degrades rapidly. Addressing this gap typically requires expensive fine-tuning using curated datasets, often targeting older or less capable model variants due to vendor restrictions or lack of access to the latest commercial models.

These challenges are particularly acute for innovators pushing the state of the art in model-based systems engineering (MBSE). As modeling languages such as SysML v2 and contract languages such as GUMBO evolve, and as verification infrastructures expand to include automated proof, code generation, and DevOps-style workflows, the availability of representative training data lags behind tool capability.

This work is motivated by the needs of the \textbf{INSPECTA toolchain}, which is being developed to automate large portions of DevOps and ProofOps across large engineering teams. INSPECTA integrates modeling, contract specification, formal verification, and code generation to enable a trustworthy MBSE lifecycle. In such an environment, reliance on brittle prompt engineering or repeated fine-tuning is impractical. Instead, mechanisms are needed to capture expert reasoning, reuse formalization knowledge, and continuously adapt to evolving tools without retraining underlying models.

%--------------------------------------------------------------------
\section{SysML v2 Tutorial}
\label{sec:sysmlv2}

\todo{This section is intentionally left empty and will be completed in a later draft.}

%--------------------------------------------------------------------
\section{GUMBO Contracts}
\label{sec:gumbo}

GUMBO is a contract language designed to express behavioral guarantees and assumptions in SysML v2 models. Contracts written in GUMBO serve as a bridge between architectural models and formal verification, enabling properties to be checked at the model, integration, and generated-code levels.

GUMBO contracts are expressive enough to capture temporal, data, and control-flow constraints while remaining amenable to automated analysis. However, authoring correct GUMBO contracts requires deep familiarity with both the modeling language and the underlying verification semantics. This expertise barrier motivates the use of AI-assisted contract generation, provided correctness and trustworthiness can be ensured.

%--------------------------------------------------------------------
\section{Neuro-Symbolic Approach to Contract Generation}
\label{sec:neurosymbolic}

Our approach combines large language models with symbolic verification tools in a closed-loop, evaluation-driven workflow.

\subsection{Use of Large Language Models}
LLMs are used to interpret natural-language requirements and propose candidate GUMBO contracts. Rather than treating the LLM as an oracle, we position it as a heuristic generator whose outputs are subject to systematic validation and refinement.

\subsection{Use of Logika and the HAMR Toolchain}
Formal verification is performed using the HAMR toolchain, which integrates Logika for contract checking and proof. HAMR enables verification at multiple levels, including architectural consistency, component integration, and generated code. Verification feedback—including counterexamples and proof failures—is returned to the synthesis process to guide refinement.

\subsection{Meta-Rules}
We introduce \emph{Meta-Rules} as a mechanism for capturing reusable formalization knowledge. A Meta-Rule encodes a generalized mapping between classes of natural-language requirements and corresponding GUMBO contract patterns.

Meta-Rules are learned from a small number of \emph{golden examples} and retained only if they lead to verifiable contracts within defined time and resource budgets. Rules can be refined through additional verification feedback or human review, enabling persistent improvement without modifying the underlying LLM.
%%-----------
%====================================================================
\section{Neuro-Symbolic Contract Generation with Meta-Rules}
\label{sec:meta-rules}

Our goal is to generate correct-by-construction (or at least \emph{correct-by-verification}) GUMBO contracts for SysML v2 models by combining LLM-based synthesis with rigorous symbolic checking. This design is motivated by the practical limitations of deploying mainstream commercial LLMs in emerging formal-methods workflows: (i) model pretraining often lags behind rapidly evolving languages and toolchains, (ii) vendor restrictions may prevent fine-tuning of the newest, most capable models, and (iii) fine-tuning older model variants requires substantial labeled data that may not exist for novel language constructs.

% Source grounding for INSPECTA/HAMR/PROVERS motivation:
% hardin2025dasc.pdf, p.1 (Introduction), INSPECTA definition and PROVERS motivation (see first page text).
% hardin2025dasc.pdf also discusses SysML v2, GUMBO, HAMR, Rust/Verus, and proof/CI pipeline context (see Sec. II--VI and figures).

To address these constraints, we treat the LLM as a \emph{proposal generator} rather than an oracle. Each candidate contract is validated against formal checks in the toolchain (e.g., HAMR/Logika-based verification) and iteratively repaired when failures occur. The key contribution is the introduction of \emph{Meta-Rules}: persistent, reusable formalization strategies that capture expert mappings from natural-language requirement patterns to GUMBO idioms, and that are retained only when they empirically generalize and verify.

% Source grounding for toolchain context and verification workflow:
% hardin2025dasc.pdf, Sec. III--IV (assume/guarantee contracts; HAMR code generation; Logika/Slang; Rust/Verus pipeline).
% Hatcliff-etal-ISOLA2024-Isolette-Overview.pdf, p.1 (Isolette artifacts; AADL+HAMR+GUMBO+Slang/Logika end-to-end).

\subsection{LLM as a Heuristic Synthesis Component}
We prompt an LLM to translate English requirements into candidate GUMBO blocks. In practice, direct prompting fails in domains where the model lacks exposure to the latest SysML v2/GUMBO semantics or project-specific idioms. Moreover, repeated self-correction can be computationally expensive and unreliable. Thus, we explicitly bound synthesis by (i) token budgets, (ii) wall-clock budgets, and (iii) a maximum number of automated repair cycles.

\subsection{Verification-Guided Repair Loop}
Each candidate GUMBO contract is checked using the verification toolchain. When verification fails (e.g., due to violated proof obligations or counterexamples), the system constructs a repair prompt that includes (a) the failing requirement(s), (b) the candidate contract, and (c) tool feedback (counterexample, error trace, or violation summary). The LLM then proposes a revised contract. This loop repeats until the contract verifies or budgets are exhausted.

% If you cite a figure for this loop from the slides:
% SCP-Codex-OpenPlatform.pptx.pdf, COMMENT HERE with page number + figure id once we lock the exact slide.
% Example: % Source: SCP-Codex-OpenPlatform.pptx.pdf, p.X, Fig.Y (SCP Copilot multi-agent loop).

\subsection{Meta-Rules: Persistent Formalization Knowledge}
Meta-Rules encode reusable transformations such as:
(i) how to introduce state variables and initialization guarantees,
(ii) how to structure \texttt{compute\_cases} to reflect conditional requirements,
(iii) how to map assumptions/guarantees into tool-acceptable patterns,
and (iv) how to preserve normalization conventions required by downstream tooling.

A Meta-Rule is derived from a \emph{golden example} consisting of an English requirement and its correct (normalized) GUMBO formalization. The system extracts a generalized mapping (the Meta-Rule) and tests its generalizability by applying it to other requirements. Only rules that produce contracts that (a) are sufficiently close to a reference normalization and (b) pass verification within resource budgets are retained in local memory. Rules may be revised by a human expert and re-evaluated before being committed.

\subsection{Meta-Rule Refinement via Evaluation}
Meta-Rules are refined using an evaluation-driven process:
\begin{compactitem}
  \item \textbf{Extraction:} infer a candidate rule from (requirement, golden contract) pairs.
  \item \textbf{Application:} apply the rule to unseen requirements to produce candidate contracts.
  \item \textbf{Evaluation:} accept the rule if resulting contracts verify (or verify after bounded repair).
  \item \textbf{Retention:} store verified rules in local memory for future runs.
\end{compactitem}
This process enables continual improvement without fine-tuning the underlying LLM.

% Source grounding for evaluation-driven neuro-symbolic copilot framing:
% main.pdf (AGREE-Dog AISOLA25), early pages describe neuro-symbolic copilot integration, memory/context selection, and evaluation metrics.
% Cite later as \cite{agreedogAISOLA25} once bib keys are in place.

%--------------------------------------------------------------------
\subsection{Algorithm}
\label{sec:meta-rule-algorithm}

Algorithm~\ref{alg:meta-rules} formalizes the Meta-Rule learning and application workflow. The algorithm assumes access to (i) a set of requirements $R$, (ii) a small set of golden examples $G$, (iii) a verifier $V$ (e.g., HAMR/Logika toolchain), and (iv) resource budgets $B$ governing time, tokens, and repair cycles.

\begin{algorithm}[t]
\caption{Meta-Rule Learning and Verification-Guided Formalization}
\label{alg:meta-rules}
\begin{algpseudocode}[1]
\Require Requirements $R$, golden examples $G$, verifier $V$, budgets $B$
\Ensure Verified contracts $C$, retained Meta-Rules $M$
\State $M \gets \emptyset$ \Comment{Meta-Rule memory}
\State $C \gets \emptyset$

\Comment{Phase 1: Learn candidate Meta-Rules from golden examples}
\ForAll{$(r_g, g_g) \in G$}
  \State $m \gets \textsc{ExtractRule}(r_g, g_g)$
  \State $score \gets 0$
  \ForAll{$r \in \textsc{Sample}(R)$}
     \State $\hat{g} \gets \textsc{ApplyRule}(m, r)$
     \State $(ok, fb) \gets V(\hat{g}, B)$
     \If{$\neg ok$}
        \State $\hat{g} \gets \textsc{Repair}(\hat{g}, fb, B)$
        \State $(ok, fb) \gets V(\hat{g}, B)$
     \EndIf
     \If{$ok$}
        \State $score \gets score + 1$
     \EndIf
  \EndFor
  \If{$score \ge \tau$}
     \State $M \gets M \cup \{m\}$ \Comment{Retain rule if it generalizes and verifies}
  \EndIf
\EndFor

\Comment{Phase 2: Apply retained Meta-Rules to full requirement set}
\ForAll{$r \in R$}
  \State $\hat{g} \gets \textsc{SynthesizeWithRules}(r, M)$
  \State $(ok, fb) \gets V(\hat{g}, B)$
  \While{$\neg ok$ \textbf{and} $\textsc{BudgetRemaining}(B)$}
     \State $\hat{g} \gets \textsc{Repair}(\hat{g}, fb, B)$
     \State $(ok, fb) \gets V(\hat{g}, B)$
  \EndWhile
  \If{$ok$}
     \State $C \gets C \cup \{(r,\hat{g})\}$
  \Else
     \State \textsc{FlagForReview}$(r, \hat{g}, fb)$
  \EndIf
\EndFor
\State \Return $C, M$
\end{algpseudocode}
\end{algorithm}

\noindent
\textbf{Discussion.} The key distinction from prompt-only baselines is the persistent and testable memory $M$ of verified rules. This shifts effort from repeated token-expensive self-correction toward reusable formalization knowledge, enabling improved efficiency and correctness under bounded resources.

%====================================================================

%--------------------------------------------------------------------
\section{Illustrative Example}
\label{sec:example}

We present an example contract derived from the current work that required one round of counterexample-driven refinement. Figure~\ref{fig:example-conversation} shows a snapshot of the SCP Copilot interaction, including self-correction following failed verification feedback.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/figure-1.png}
  \caption{Example SCP Copilot interaction illustrating Meta-Rule–guided contract generation and refinement following verification feedback.}
  \label{fig:example-conversation}
\end{figure*}

%--------------------------------------------------------------------
\section{Results}
\label{sec:results}

We evaluated the approach on a benchmark of natural-language requirements drawn from open-source instructional documentation. Metrics include verification success rate, token consumption, reasoning overhead, and time to convergence. Results demonstrate substantial improvements over baseline LLM-driven approaches, achieving full verification with significantly reduced computational cost.

%--------------------------------------------------------------------
\section{Related Work}
\label{sec:related}

Related work spans neuro-symbolic reasoning, program synthesis, contract-based design, and AI-assisted formal methods. Prior approaches often rely on extensive fine-tuning or domain-specific datasets. In contrast, our work emphasizes evaluation-driven knowledge reuse and toolchain integration.

%--------------------------------------------------------------------
\section{Conclusion and Future Work}
\label{sec:conclusion}

This paper presents an evaluation-driven neuro-symbolic approach to contract generation that avoids fine-tuning and adapts to evolving modeling ecosystems. Meta-Rules enable reusable, verifiable formalization knowledge, supporting scalable and trustworthy MBSE workflows. Future work includes expanding the rule library, extending to additional domains, and tighter integration with evolving INSPECTA capabilities.

%--------------------------------------------------------------------
\section*{Acknowledgment}
This work was funded by DARPA contract FA8750-24-9-1000. The views, opinions, and findings expressed are those of the authors and do not necessarily reflect the official views or policies of the U.S. Department of Defense or the U.S. Government.

\bibliographystyle{IEEEtran}
\bibliography{biblio}

\end{document}
